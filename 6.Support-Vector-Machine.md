# Support Vector machines

The Support Vector Machine (SVM) is yet another type of supervised machine learning algorithm. It is sometimes cleaner and more powerful.

We will understand mathematical intuition of svm using Logistic Regression.

![Logistic Regression](pics/svm/recall-LR.png)

To make Support Vector Machine, we need to modify the cost function of Regularized Logistic Regression.
![Modify Logistic Regression](pics/svm/modify-LR-to-svm.png)

for values of z less than 1, we shall use a straight decreasing line instead of the sigmoid curve.(In the literature, this is called a hinge loss (https://en.wikipedia.org/wiki/Hinge_loss) function.)

for values of z greater than -1, we use a straight increasing line instead of the sigmoid curve.


![Modify Logistic Regression](pics/svm/modify-LR-to-svm2.png)

We shall denote these as cost1(z) and cost0(z) (respectively, note that cost1(z) is the cost for classifying when y=1, and cost0(z) is the cost for classifying when y=0), and we may define them as follows (where k is an arbitrary constant defining the magnitude of the slope of the line)

We can optimize cost function a bit by multiplying by m (thus removing the m factor in the denominators). Note that this does not affect our optimization, since we're simply multiplying our cost function by a positive constant (for example, minimizing (u−5)<sup>2</sup>+1 gives us 5; multiplying it by 10 to make it 10(u−5)<sup>2</sup>+10 still gives us 5 when minimized).
